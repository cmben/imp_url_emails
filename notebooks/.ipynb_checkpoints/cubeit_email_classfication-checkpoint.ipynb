{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn\n",
    "seaborn.set()\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Task Description\n",
    "The task is to identify links in email data which are important or relevant to emails, and links which are not important and irrelavant to email. For example, if there is a link in a body of the message regarding work, it should be important. And link which is just a part of the footer, ex, personal blog of the sender, is not so important.\n",
    "\n",
    "Lets use some public dataset for the same. We will be using a spam classification dataset available here http://spamassassin.apache.org/publiccorpus/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 110M\r\n",
      "-rw-rw-r-- 1 zopnow zopnow  233 Aug  8 17:41 1000\r\n",
      "-rw-rw-r-- 1 zopnow zopnow 1.1K Aug  8 17:41 1001\r\n",
      "-rw-rw-r-- 1 zopnow zopnow  993 Aug  8 17:41 1002\r\n",
      "-rw-rw-r-- 1 zopnow zopnow 2.1K Aug  8 17:41 1003\r\n",
      "-rw-rw-r-- 1 zopnow zopnow 2.7K Aug  8 17:41 1004\r\n",
      "-rw-rw-r-- 1 zopnow zopnow 4.3K Aug  8 17:41 1005\r\n",
      "-rw-rw-r-- 1 zopnow zopnow 1.8K Aug  8 17:41 1006\r\n",
      "-rw-rw-r-- 1 zopnow zopnow 1.7K Aug  8 17:41 1007\r\n",
      "-rw-rw-r-- 1 zopnow zopnow 3.5K Aug  8 17:41 1008\r\n",
      "ls: write error\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh ../myemails/ | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each email has some headers and message body. Headers may be important in some cases such as spam classification, but for the task we are solving, we can get rid of all the headers. \n",
    "Run following python script which parses all messages and extracts only email body. Each email is a long string. And the output is list of emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def loadAndExtractMessage(filename):\n",
    "    email = open(filename, \"r\")\n",
    "    message = email.readlines()\n",
    "    #This is only applicable if you have headers in email, comment out if you dont have headers.\n",
    "    first_blank_index = message.index('\\n') if '\\n' in message else 0\n",
    "    first_signature_index = min(message.index('-- \\n', first_blank_index) if '-- \\n' in message else len(message),\n",
    "                                message.index('___\\n', first_blank_index) if '___\\n' in message else len(message),\n",
    "                                message.index('--\\n', first_blank_index) if '--\\n' in message else len(message), \n",
    "                                message.index('-----Original Message-----\\n', first_blank_index) if '-----Original Message-----\\n' in message else len(message), \n",
    "                                message.index('________________________________', first_blank_index) if '________________________________' in message else len(message),\n",
    "                                message.index('From: ', first_blank_index) if 'From: ' in message else len(message), \n",
    "                                message.index('Sent from my ', first_blank_index) if 'Sent from my ' in message else len(message))\n",
    "    message = message[(first_blank_index+1):(first_signature_index)]\n",
    "    #cases to handle, remove quoted text\n",
    "    return ''.join(message)\n",
    "\n",
    "def getEmailsFromDir(path):\n",
    "    filelist = os.listdir(path)\n",
    "    filelist = filter(lambda x: x != 'cmds', filelist)\n",
    "    all_messages = [loadAndExtractMessage(os.path.join(path, f)) for f in filelist]\n",
    "    return all_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_messages = getEmailsFromDir('../easy_ham/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Kragen,\n",
      "\n",
      "   This is an interesting analysis.  I think that there are a couple\n",
      "of nits I might pick (for example, I don't expect that the market will\n",
      "be well developed with highest bidders for while), I think that the\n",
      "most important issue, which is that end users won't be able to fix\n",
      "their systems, is almost passed over.  I know that you know this, and\n",
      "you allude to it, but your essay is getting passed around, so you\n",
      "might want to add to it bits about the sysadmin and others.\n",
      "\n",
      "   There's one other point which you don't make, which I think is very\n",
      "important, which is that research into defining and addressing classes\n",
      "of vulnerabilities can't happen without libraries of available\n",
      "vulnerability code.  I can think of three researchers into automated\n",
      "methods for addressing vulnerabilities who griped, uninvited, about\n",
      "the quality of the existing vulnerability sites.  Doing research into\n",
      "a set requires that you have enough examples, in the open, that you\n",
      "can define a set, and that the set is added to from time to time so\n",
      "you can make and test predictions.\n",
      "\n",
      "   I feel fairly confident in saying that without full disclosure, we\n",
      "wouldn't have Stackguard, ITS4, Nissus, or snort.  And the security\n",
      "admin's job would be a lot harder.\n",
      "\n",
      "Adam\n",
      "\n",
      "\n",
      "On Thu, Aug 22, 2002 at 08:42:12AM +0200, Eugen Leitl wrote:\n",
      "| -- \n",
      "| -- Eugen* Leitl <a href=\"http://leitl.org\">leitl</a>\n",
      "| ______________________________________________________________\n",
      "| ICBMTO: N48 04'14.8'' E11 36'41.2'' http://eugen.leitl.org\n",
      "| 83E5CA02: EDE4 7193 0833 A96B 07A7  1A88 AA58 0E89 83E5 CA02\n",
      "| \n",
      "| \n",
      "| ---------- Forwarded message ----------\n",
      "| Date: Thu, 22 Aug 2002 00:24:54 -0400 (EDT)\n",
      "| From: Kragen Sitaker <kragen@pobox.com>\n",
      "| To: fork@example.com\n",
      "| Subject: the underground software vulnerability marketplace and its hazards\n",
      "| \n",
      "| On August 7th, an entity known as \"iDEFENSE\" sent out an announcement,\n",
      "| which is appended to this email.  Briefly, \"iDEFENSE\", which bills\n",
      "| itself as \"a global security intelligence company\", is offering cash\n",
      "| for information about security vulnerabilities in computer software\n",
      "| that are not publicly known, especially if you promise not to tell\n",
      "| anyone else.\n",
      "| \n",
      "| If this kind of secret traffic is allowed to continue, it will pose a\n",
      "| very serious threat to our computer communications infrastructure.\n",
      "| \n",
      "| At the moment, the dominant paradigm for computer security research\n",
      "| known as \"full disclosure\"; people who discover security\n",
      "| vulnerabilities in software tell the vendor about them, and a short\n",
      "| while later --- after the vendor has had a chance to fix the problem\n",
      "| --- they publish the information, including code to exploit the\n",
      "| vulnerability, if possible.  \n",
      "| \n",
      "| This method has proven far superior to the old paradigm established by\n",
      "| CERT in the late 1980s, which its proponents might call \"responsible\n",
      "| disclosure\" --- never release working exploit code, and never release\n",
      "| any information on the vulnerability before all vendors have released\n",
      "| a patch.  This procedure often left hundreds of thousands of computers\n",
      "| vulnerable to known bugs for months or years while the vendors worked\n",
      "| on features, and often, even after the patches were released, people\n",
      "| wouldn't apply them because they didn't know how serious the problem\n",
      "| was.\n",
      "| \n",
      "| The underground computer criminal community would often discover and\n",
      "| exploit these same holes for months or years while the \"responsible\n",
      "| disclosure\" process kept their victims, who had no connections in the\n",
      "| underground, vulnerable.\n",
      "| \n",
      "| The problem with this is that vulnerabilities that are widely known\n",
      "| are much less dangerous, because their victims can take steps to\n",
      "| reduce their potential impact --- including disabling software,\n",
      "| turning off vulnerable features, filtering traffic in transit, and\n",
      "| detecting and responding to intrusions.  They are therefore much less\n",
      "| useful to would-be intruders.  Also, software companies usually see\n",
      "| security vulnerabilities in their software as PR problems, and so\n",
      "| prefer to delay publication (and the expense of fixing the bugs) as\n",
      "| long as possible.\n",
      "| \n",
      "| iDEFENSE is offering a new alternative that appears far more dangerous\n",
      "| than either of the two previous paradigms.  They want to be a buyer in\n",
      "| a marketplace for secret software vulnerability information, rewarding\n",
      "| discoverers of vulnerabilities with cash.  \n",
      "| \n",
      "| Not long before, Snosoft, a group of security researchers evidently\n",
      "| including some criminal elements, apparently made an offer to sell the\n",
      "| secrecy of some software vulnerability information to the software\n",
      "| vendor; specifically, they apparently made a private offer to\n",
      "| Hewlett-Packard to keep a vulnerability in HP's Tru64 Unix secret if\n",
      "| HP retained Snosoft's \"consulting services\".  HP considered this\n",
      "| extortion and responded with legal threats, and Snosoft published the\n",
      "| information.\n",
      "| \n",
      "| If this is allowed to happen, it will cause two problems which,\n",
      "| together, add up to a catastrophe.\n",
      "| \n",
      "| First, secret software vulnerability information will be available to\n",
      "| the highest bidder, and to nobody else.  For reasons explained later,\n",
      "| I think the highest bidders will generally be organized crime\n",
      "| syndicates, although that will not be obvious to the sellers.\n",
      "| \n",
      "| Second, finding software vulnerabilities and keeping them secret will\n",
      "| become lucrative for many more talented people.  The result will be\n",
      "| --- just as in the \"responsible disclosure\" days --- that the good\n",
      "| guys will remain vulnerable for months and years, while the majority\n",
      "| of current vulnerabilities are kept secret.\n",
      "| \n",
      "| I've heard it argued that the highest bidders will generally be the\n",
      "| vendors of the vulnerable software, but I don't think that's\n",
      "| plausible.  If someone can steal $20 000 because a software bug lets\n",
      "| them, the software vendor is never held liable; often, in fact, the\n",
      "| people who administer the software aren't liable, either --- when\n",
      "| credit card data are stolen from an e-commerce site, for example.\n",
      "| Knowing about a vulnerability before anyone else might save a web-site\n",
      "| administrator some time, and it might save the software vendor some\n",
      "| negative PR, but it can net the thief thousands of dollars.\n",
      "| \n",
      "| I think the highest bidders will be those for whom early vulnerability\n",
      "| information is most lucrative --- the thieves who can use it to\n",
      "| execute the largest heists without getting caught.  Inevitably, that\n",
      "| means organized crime syndicates, although the particular gangs who\n",
      "| are good at networked theft may not yet exist.\n",
      "| \n",
      "| There might be the occasional case where a market leader, such as\n",
      "| Microsoft, could make more money by giving their competitors bad PR\n",
      "| than a gang could make by theft.  Think of a remote-root hole in\n",
      "| Samba, for example.\n",
      "| \n",
      "| Right now, people who know how to find security exploits are either\n",
      "| motivated by personal interest in the subject, motivated by the public\n",
      "| interest, motivated by a desire for individual recognition, or\n",
      "| personally know criminals that benefit from their exploits.  Creating\n",
      "| a marketplace in secret vulnerability information would vastly\n",
      "| increase the availability of that information to the people who can\n",
      "| afford to pay the most for it: spies, terrorists, and organized crime.\n",
      "| \n",
      "| Let's not let that happen.\n",
      "| \n",
      "| \n",
      "| \n",
      "| \n",
      "| This is the original iDEFENSE announcement:\n",
      "| \n",
      "| From: Sunil James [mailto:SJames@iDefense.com]\n",
      "| Sent: Wednesday, August 07, 2002 12:32 PM\n",
      "| Subject: Introducing iDEFENSE's Vulnerability Contributor Program\n",
      "| \n",
      "| \n",
      "| Greetings,\n",
      "| \n",
      "| iDEFENSE is pleased to announce the official launch of its Vulnerability\n",
      "| Contributor Program (VCP). The VCP pays contributors for the advance\n",
      "| notification of vulnerabilities, exploit code and malicious code.\n",
      "| \n",
      "| iDEFENSE hopes you might consider contributing to the VCP. The following\n",
      "| provides answers to some basic questions about the program:\n",
      "| \n",
      "| Q. How will it work?\n",
      "| A. iDEFENSE understands the majority of security researchers do not publish\n",
      "| security research for compensation; rather, it could be for any of a number\n",
      "| of motivations, including the following:\n",
      "| \n",
      "|          * Pure love of security research\n",
      "|          * The desire to protect against harm to targeted networks\n",
      "|          * The desire to urge vendors to fix their products\n",
      "|          * The publicity that often accompanies disclosure\n",
      "| \n",
      "| The VCP is for those who want to have their research made public to the\n",
      "| Internet community, but who would also like to be paid for doing the\n",
      "| work.The compensation will depend, among other things, on the following\n",
      "| items:\n",
      "| \n",
      "|          * The kind of information being shared (i.e. vulnerability or exploit)\n",
      "|          * The amount of detail and analysis provided\n",
      "|          * The potential severity level for the information shared\n",
      "|          * The types of applications, operating systems, and other\n",
      "|            software and hardware potentially affected\n",
      "|          * Verification by iDEFENSE Labs\n",
      "|          * The level of exclusivity, if any, for data granted to iDEFENSE\n",
      "| \n",
      "| Q. Who should contribute to the VCP?\n",
      "| A. The VCP is open to any individual, security research group or other\n",
      "| entity.\n",
      "| \n",
      "| Q. Why are you launching this program?\n",
      "| A. Timeliness remains a key aspect in security intelligence. Contributions\n",
      "| to some lists take time before publication to the public at large. More\n",
      "| often, many of these services charge clients for access without paying the\n",
      "| original contributor. Under the iDEFENSE program, the contributor is\n",
      "| compensated, iDEFENSE Labs verifies the issue, and iDEFENSE clients and the\n",
      "| public at large are warned in a timely manner.\n",
      "| \n",
      "| Q. Who gets the credit?\n",
      "| A. The contributor is always credited for discovering the vulnerability or\n",
      "| exploit information.\n",
      "| \n",
      "| Q. When can I contribute?\n",
      "| The VCP is active. You are welcome to begin contributing today.\n",
      "| \n",
      "| To learn more, go to http://www.idefense.com/contributor.html. If you have\n",
      "| questions or would like to sign up as a contributor to the VCP, please\n",
      "| contact us at contributor@idefense.com.\n",
      "| \n",
      "| Regards,\n",
      "| \n",
      "| Sunil James\n",
      "| Technical Analyst\n",
      "| iDEFENSE\n",
      "| \n",
      "| \"iDEFENSE is a global security intelligence company that proactively\n",
      "| monitors sources throughout the world -- from technical vulnerabilities and\n",
      "| hacker profiling to the global spread of viruses and other malicious code.\n",
      "| The iALERT security intelligence service provides decision-makers, frontline\n",
      "| security professionals and network administrators with timely access to\n",
      "| actionable intelligence and decision support on cyber-related threats.\n",
      "| iDEFENSE Labs is the research wing that verifies vulnerabilities, examines\n",
      "| the behavior of exploits and other malicious code and discovers new\n",
      "| software/hardware weaknesses in a controlled lab environment.\"\n",
      "| \n",
      "| http://xent.com/mailman/listinfo/fork\n",
      "| \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print all_messages[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The importance of link depends upon where it is placed in text. That means, sequence of words before and after the link matters and they largely decide whether link is important. For example, \n",
    "1. Please see the below link \"http://www.google.com\"\n",
    "2. Regards, Chaitanya Bendre \"http://chaitanya.com\"\n",
    "\n",
    "In the above text, first link is important and second link not since it only describes personal link of the sender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, lets process each input message. We will do following things in sequence on this messages.\n",
    "1. Remove '3D' character and HTML tags\n",
    "2. Remove newline characters\n",
    "3. Replace Multiple underscores with a single one\n",
    "4. Remove '=\\n' symbols from text, since they sometimes appear to indicate line wrapping.\n",
    "5. Remove stopwords such as 'a','and','the'\n",
    "6. Remove puncuation tokens, numbers and single letters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_msg_words(message, strip_html = False):\n",
    "    #remove 3D character\n",
    "    message = re.sub('3D','', message)\n",
    "    \n",
    "    # Strip out html tags and attributes and html character codes,\n",
    "    # like &nbsp; and &lt;.\n",
    "    if strip_html:\n",
    "        message = re.sub('<(.|\\n)*?>', ' ', message)\n",
    "        message = re.sub('&\\w+;', ' ', message)\n",
    "    \n",
    "    #replace multiple underscores with single \n",
    "    message = re.sub('_+', '_', message)\n",
    "    \n",
    "    # remove '=' symbols before tokenizing, since these are\n",
    "    # sometimes occur within words to indicate, e.g., line-wrapping.\n",
    "    message = message.replace('=\\n', '')\n",
    "    \n",
    "    # Get rid of stopwords\n",
    "    #remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    msg_words = [word for word in message.lower().split() if word not in stop_words]\n",
    "    \n",
    "    #remove puncuation, numbers \n",
    "    msg_words = [w for w in msg_words if re.search('[a-zA-Z]', w) ]\n",
    "    \n",
    "    return msg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fri,', 'feb', '12:42:02pm', 'brian', 'french', 'wrote:', 'hey', 'problem:', 'rpms', 'installed', 'want', 'uninstall,', 'like', 'so:', 'rpm', '-e', '[rpm', 'package]', 'gives', 'error:', 'package', 'installed,', 'install', 'like', 'so:', 'little', 'confusing', 'install', 'rpms', 'like', 'rpm', '-ivh', 'packagename-0.1.1.rpm', 'uninstalls', 'must', 'done', 'without', 'version', 'info', 'like', 'rpm', '-e', 'packagename', 'ie:', 'rpm', '-e', 'sendmail', 'rpm', '-e', 'sendmail-devel.', 'give', 'go', 'work', 'np.', 'phil,', 'rpm', '-i', '[rpm', 'package]', 'gives', 'error:', 'package', 'already', 'installed,', 'force', 'install', 'like', 'so:', 'rpm', '-i', '--force', '[rpm', 'package]', 'installs', 'try', 'uninstall', 'still', 'gives', 'error:', 'package', 'installed.', 'get', 'recognize', 'package', 'indeed', 'installed', 'it,', 'and/or', 'get', 'unstall', 'it?', 'thanx', 'advance,', 'brian', 'french', '-french', 'rpm-list', 'mailing', 'list', 'http://lists.freshrpms.net/mailman/listinfo/rpm-list']\n"
     ]
    }
   ],
   "source": [
    "words = get_msg_words(all_messages[2], strip_html=True)\n",
    "print words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tested our function, next step is analysing this links to find important ones.\n",
    "Lets run one basic analysis, which is getting TF-IDF matrix of all words, and getting the words which starts with http://. We will sort them by tfidf score and print top ones. Of course, this approach regards all links in the email as same, wherever they are placed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAllMessagesAfterCleaning(all_messages):\n",
    "    data = []\n",
    "    for msg in all_messages:\n",
    "        words = get_msg_words(msg, strip_html=True)\n",
    "        data.append(words)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'all,',\n",
       " \"i'm\",\n",
       " 'trying',\n",
       " 'set',\n",
       " 'following:',\n",
       " 'linux',\n",
       " 'server',\n",
       " 'running',\n",
       " 'modem',\n",
       " 'internet',\n",
       " 'connectivity',\n",
       " 'ethernet',\n",
       " 'card',\n",
       " 'lan',\n",
       " 'connectivity',\n",
       " 'lan',\n",
       " 'pcs',\n",
       " 'ethernet',\n",
       " 'cards,',\n",
       " 'using',\n",
       " 'linux',\n",
       " 'server',\n",
       " 'dns/dhcp',\n",
       " 'etc.',\n",
       " 'basically,',\n",
       " 'want',\n",
       " 'route',\n",
       " 'non',\n",
       " 'lan',\n",
       " 'traffic',\n",
       " 'ppp0.',\n",
       " \"i've\",\n",
       " 'got',\n",
       " 'way,',\n",
       " 'like',\n",
       " 'similar',\n",
       " 'post',\n",
       " 'earlier',\n",
       " 'modem',\n",
       " 'problems,',\n",
       " 'connected',\n",
       " 'internet',\n",
       " 'eht0',\n",
       " 'up,',\n",
       " 'routing',\n",
       " 'incorrect',\n",
       " 'noting',\n",
       " 'goes',\n",
       " 'ppp0',\n",
       " '(eh0',\n",
       " 'must',\n",
       " 'default',\n",
       " 'route',\n",
       " 'something).',\n",
       " 'standard',\n",
       " '\"out',\n",
       " 'box\"',\n",
       " 'linux',\n",
       " 'tools',\n",
       " 'carry',\n",
       " 'portmapping',\n",
       " 'behalf',\n",
       " 'lan',\n",
       " 'pcs',\n",
       " \"(i'm\",\n",
       " 'planning',\n",
       " 'non',\n",
       " 'routable',\n",
       " 'addresses',\n",
       " '192.168.x.x',\n",
       " 'lan,',\n",
       " 'routed',\n",
       " 'outwards',\n",
       " 'via',\n",
       " 'ppp0',\n",
       " 'interface).',\n",
       " 'someone',\n",
       " 'point',\n",
       " 'right',\n",
       " 'howtos',\n",
       " 'routing',\n",
       " 'documentation',\n",
       " 'need',\n",
       " 'follow',\n",
       " 'thanks,',\n",
       " 'dermot.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = getAllMessagesAfterCleaning(all_messages)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not Lets extract links from each item in datasets making two lists. Data list will contain that preceed the link. And label list will have name of the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractlinksfromdataset(dataset, numwords = 10):\n",
    "    newdataset = []\n",
    "    datalabels = []\n",
    "    for data in dataset:\n",
    "        starts = [n for n,l in enumerate(data) if l.startswith('http://')]\n",
    "        for index in starts:\n",
    "            newdataset.append(' '.join(data[(index-numwords):index] + data[(index+1):(index+numwords+1)]))\n",
    "            datalabels.append(data[index])\n",
    "    return newdataset, datalabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdataset, linklabels = extractlinksfromdataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['08:42:12am eugen leitl wrote: eugen* leitl leitl icbmto: n48 e11 83e5ca02: ede4 a96b 07a7 1a88 aa58 0e89 83e5 ca02 forwarded',\n",
       " 'contribute? vcp active. welcome begin contributing today. learn more, go questions would like sign contributor vcp, please contact us contributor@idefense.com.',\n",
       " 'exploits malicious code discovers new software/hardware weaknesses controlled lab environment.\"']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://eugen.leitl.org',\n",
       " 'http://www.idefense.com/contributor.html.',\n",
       " 'http://xent.com/mailman/listinfo/fork']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linklabels[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will make a Term Frequency corpus of these docs. Our intuition is that links which are not important will appear more than once in the same context. For example, whenever comment appears on facebook or google group. Or if the link is part of some standard promotional mails. Having similar words before and after link, these links will be similar and form cluster. Therefore, links which do not fall into any cluster are outliers. And we will treat them as important links.\n",
    "\n",
    "How do we detect outliers from clusters ? There are several approaches, but we will try two of them. \n",
    "1. Robust Estimator of co-variance\n",
    "2. One-class SVM.\n",
    "http://scikit-learn.org/stable/auto_examples/covariance/plot_outlier_detection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english', decode_error='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectordata = vectorizer.fit_transform(newdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2968"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(linklabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2968, 8001)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "outliers_fraction = 0.95\n",
    "clf = svm.OneClassSVM(nu = 0.95 * outliers_fraction + 0.05, kernel='rbf', gamma=0.1)\n",
    "clf.fit(vectordata)\n",
    "y_pred = clf.decision_function(vectordata).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.62039069e+294,  -1.60145404e+294,  -1.58811892e+294, ...,\n",
       "        -1.53777594e+294,  -1.62039052e+294,  -1.62038711e+294])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "threshold = stats.scoreatpercentile(y_pred, 100 * outliers_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "imp_links = list(compress(linklabels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imp_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.post-gazette.com/columnists/20020905brian5.asp',\n",
       " 'http://www.newsisfree.com/click/-2,8424915,1717/',\n",
       " 'http://www.newsisfree.com/click/-4,8293089,1717/',\n",
       " 'http://www.osnews.com/story.php?news_id=1890',\n",
       " 'http://www.aaronsw.com/weblog/000647',\n",
       " 'http://infomesh.net/2002/swhaiku/',\n",
       " 'http://weblog.burningbird.net/archives/000581.php',\n",
       " 'http://www.dooce.com/mtarchives/10_08_2002.html',\n",
       " 'http://www.elegantwomen.net/mirasorvino/009.html',\n",
       " 'http://www.safesearching.com/portiaderossi/gallery/',\n",
       " 'http://images.amazon.com/images/p/0792846486.01.lzzzzzzz.jpg',\n",
       " 'http://www.elegantwomen.net/jeriryan/003.html',\n",
       " 'http://www.stylenetwork.com/shows/nigella/gallery/index.html',\n",
       " 'http://www.elegantwomen.net/angelinajolie/009.html',\n",
       " 'http://bitworking.org/oct2002.html#x631695997519494480',\n",
       " 'http://www.winterspeak.com/columns/082001.html',\n",
       " 'http://www.annoyances.org/exec/show/article02-013',\n",
       " 'http://www.mozilla.org/',\n",
       " 'http://www.gnu.org/software/emacs/windows/ntemacs.html',\n",
       " 'http://www.activestate.com/products/activepython/',\n",
       " 'http://www.lavasoftusa.com/',\n",
       " 'http://www.openoffice.org/',\n",
       " 'http://sillydog.org/narchive/',\n",
       " 'http://gpoulose.home.att.net/',\n",
       " 'http://www.vmware.com/',\n",
       " 'http://www.openoffice.org/',\n",
       " 'http://www.cygwin.com/',\n",
       " 'http://diveintomark.org/mt/mt-search.cgi',\n",
       " 'http://www.ultraedit.com/downloads/index.html#notepad',\n",
       " 'http://www.microsoft.com/ntworkstation/downloads/powertoys/networking/nttweakui.asp',\n",
       " 'http://www.cygwin.com/',\n",
       " 'http://www.guidescope.com/',\n",
       " 'http://download.com.com/3000-2092-10039884.html?part=zonealarm&subj=dlpage',\n",
       " 'http://philringnalda.com/archives/002337.php',\n",
       " 'http://www.bradchoate.com/past/mtsanitize.php',\n",
       " 'http://john.beimler.org/archives/000058.html',\n",
       " 'http://www.macosxhints.com/article.php?story=2002100306134721',\n",
       " 'http://weblog.burningbird.net/class_rdql/query.htm',\n",
       " 'http://weblog.burningbird.net/archives/000568.php',\n",
       " 'http://www.ideaspace.net/users/wkearney/misc/radio/radio8/rdf/current/',\n",
       " 'http://ftrain.com/second_toothpaste.html',\n",
       " 'http://www.newsisfree.com/click/-4,8268032,1717/',\n",
       " 'http://spineless.org/~mod/pix/octobermoon.jpg',\n",
       " 'http://www.newsisfree.com/click/-4,8272608,1717/',\n",
       " 'http://www.newsisfree.com/click/-2,8417754,1717/',\n",
       " 'http://www.newsisfree.com/click/-1,8410271,1717/',\n",
       " 'http://www.newsisfree.com/click/-4,8290377,1717/',\n",
       " 'http://www.newsisfree.com/click/-1,8406746,1717/',\n",
       " 'http://www.dashes.com/anil/index.php?archives/003183.php',\n",
       " 'http://www.dashes.com/anil/xmlindex.php',\n",
       " 'http://q.queso.com/index.php?archives/001000.php',\n",
       " 'http://www.aquarionics.com/nodes/view.php?name=esf',\n",
       " 'http://www.intertwingly.net/blog/',\n",
       " 'http://weblog.burningbird.net/archives/000544.php',\n",
       " 'http://www.newsisfree.com/quiz/0,7476,349695,00.html',\n",
       " 'http://www.newsisfree.com/crossword/0,4406,180778,00.html',\n",
       " 'http://www.newsisfree.com/interactive/0,2759,192055,00.html',\n",
       " 'http://www.newsisfree.com/cartoons/0,7371,337484,00.html',\n",
       " 'http://www.newsisfree.com/weblog/0,6798,517233,00.html',\n",
       " 'http://www.newsisfree.com/military/story/0,11816,801625,00.html',\n",
       " 'http://www.newsisfree.com/click/-5,8535464,215/',\n",
       " 'http://boingboing.net/#85534328',\n",
       " 'http://www.newsisfree.com/quiz/0,7476,349695,00.html',\n",
       " 'http://www.newsisfree.com/crossword/0,4406,180778,00.html',\n",
       " 'http://www.newsisfree.com/interactive/0,2759,192055,00.html',\n",
       " 'http://www.newsisfree.com/cartoons/0,7371,337484,00.html',\n",
       " 'http://www.newsisfree.com/weblog/0,6798,517233,00.html',\n",
       " 'http://www.newsisfree.com/northern_ireland/story/0,2763,808962,00.html',\n",
       " 'http://www.newsisfree.com/click/-1,8398676,1717/',\n",
       " 'http://www.newsisfree.com/click/-2,8419990,1717/',\n",
       " 'http://www.newsisfree.com/click/-4,8274142,1717/',\n",
       " 'http://www.newsisfree.com/click/-1,8412059,1717/',\n",
       " 'http://www.newsisfree.com/click/-4,8268033,1717/',\n",
       " 'http://www.newsisfree.com/click/-4,8269406,1717/',\n",
       " 'http://www.newsisfree.com/click/-2,8417753,1717/',\n",
       " 'http://www.newsisfree.com/click/-4,8268029,1717/',\n",
       " 'http://www.newsisfree.com/click/-4,8259315,1717/',\n",
       " 'http://www.newsisfree.com/click/-1,8390119,1717/',\n",
       " 'http://www.dooce.com/about.html',\n",
       " 'http://howto.looselycoupled.com/blog/2002_09_22_dy.htm#85480973',\n",
       " 'http://rss.benhammersley.com/archives/001387.html',\n",
       " 'http://www-106.ibm.com/developerworks/library/wa-xhtml/?n-wa-9192',\n",
       " 'http://web.resource.org/rss/1.0/modules/cc/',\n",
       " 'http://weblog.burningbird.net/archives/000541.php',\n",
       " 'http://groups.yahoo.com/group/rss-dev/',\n",
       " 'http://burningbird.net/cgi-bin/mt-comments.cgi?entry_id=541',\n",
       " 'http://ln.hixie.ch/?start=1032794857&count=1',\n",
       " 'http://www.newsisfree.com/click/-1,8396718,1717/',\n",
       " 'http://www.newsisfree.com/click/-1,8390122,1717/',\n",
       " 'http://www.msnbc.com/news/818195.asp',\n",
       " 'http://www.nytimes.com/2002/10/08/opinion/08krug.html',\n",
       " 'http://www.nytimes.com/2002/10/08/business/08memo.html',\n",
       " 'http://www.business2.com/b2100/0,,1-1,00.html',\n",
       " 'http://www.nytimes.com/2002/10/07/business/07plac.html',\n",
       " 'http://www.msnbc.com/news/818195.asp',\n",
       " 'http://www.nytimes.com/2002/10/08/opinion/08krug.html',\n",
       " 'http://www.nytimes.com/2002/10/08/business/08memo.html',\n",
       " 'http://www.business2.com/b2100/0,,1-1,00.html',\n",
       " 'http://www.nytimes.com/2002/10/07/business/07plac.html',\n",
       " 'http://crackmice.com/mailman/listinfo/crackmice',\n",
       " 'http://www.newsisfree.com/click/-2,8423195,1717/',\n",
       " 'http://www.newsisfree.com/click/-5,8298180,1717/',\n",
       " 'http://cgi.ebay.com/aw-cgi/ebayisapi.dll?mfcisapicommand=viewitem&item=1764085998',\n",
       " 'http://www.newsisfree.com/quiz/0,7476,349695,00.html',\n",
       " 'http://www.newsisfree.com/crossword/0,4406,180778,00.html',\n",
       " 'http://www.newsisfree.com/interactive/0,2759,192055,00.html',\n",
       " 'http://www.newsisfree.com/cartoons/0,7371,337484,00.html',\n",
       " 'http://www.newsisfree.com/weblog/0,6798,517233,00.html',\n",
       " 'http://www.newsisfree.com/refugees_in_britain/story/0,2763,805011,00.html',\n",
       " 'http://energycommerce.house.gov/107/hearings/09252002hearing719/hearing.htm',\n",
       " 'http://www.newsisfree.com/click/-4,8288879,1717/',\n",
       " 'http://boingboing.net/#85534328',\n",
       " 'http://www.daypop.com/top/',\n",
       " 'http://www.newsisfree.com/click/-1,8398677,1717/',\n",
       " 'http://www.newsisfree.com/click/-3,8256507,1717/',\n",
       " 'http://www.newsisfree.com/click/-1,8412058,1717/',\n",
       " 'http://eldred.cc/',\n",
       " 'http://www.bordersstores.com/events/event_detail.jsp?seid=15127444',\n",
       " 'http://www.newsisfree.com/click/-5,8304313,1717/',\n",
       " 'http://www.google.com/search?q=mark',\n",
       " 'http://www.pradnetwork.com/affiliate.htm',\n",
       " 'http://uber.nu/2001/04/06/',\n",
       " 'http://www.google.com/search?q=%22go+to+hell%22',\n",
       " 'http://www.microsoft.com/',\n",
       " 'http://www.google.com/search?q=talentless+hack',\n",
       " 'http://www.ohmessylife.com/',\n",
       " 'http://www.webmasterworld.com/forum3/5646.htm',\n",
       " 'http://www.webmasterworld.com/forum3/5688.htm',\n",
       " 'http://www.webmasterworld.com/forum3/5723.htm',\n",
       " 'http://www.google.com/search?q=gimli+site%3adiveintomark.org',\n",
       " 'http://diveintomark.org/archives/2002/07/29.html',\n",
       " 'http://www.google.com/search?q=reservation+hotel',\n",
       " 'http://www.venere.it/home/italy.html',\n",
       " 'http://www.venere.it/',\n",
       " 'http://www.google.com/search?q=news+observer+nc',\n",
       " 'http://www.news-observer.com/',\n",
       " 'http://www.linkslsgolfworld.com/king-arthur-knight-of-the-round-table.htm',\n",
       " 'http://www.nando.net/nt/nao/',\n",
       " 'http://www.google.com/search?q=eminem',\n",
       " 'http://www.alltheweb.com/',\n",
       " 'http://www.alltheweb.com/search?query=eminem',\n",
       " 'http://www.newsisfree.com/click/-1,8390121,1717/',\n",
       " 'http://www.newsisfree.com/click/-2,8423196,1717/',\n",
       " 'http://www.newsisfree.com/quiz/0,7476,349695,00.html',\n",
       " 'http://www.newsisfree.com/crossword/0,4406,180778,00.html',\n",
       " 'http://www.newsisfree.com/interactive/0,2759,192055,00.html',\n",
       " 'http://www.newsisfree.com/cartoons/0,7371,337484,00.html',\n",
       " 'http://www.newsisfree.com/weblog/0,6798,517233,00.html',\n",
       " 'http://www.newsisfree.com/observer/crimedebate/story/0,12079,805631,00.html']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_links[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ok, we got some results. The model has captured some important links as checked manually. But it also seems like it has captured some spam links, irrelavant links as well. There can be number of explanations for this, \n",
    "1. We have not tuned parameters of OneSVM properly. We can optimize them.\n",
    "2. We havent cleaned our data properly. Some signatures are still present. And quoted text is present too.\n",
    "3. We are just considering term frequencies as a measure for calculating distances between two samples. May we can normalize them before running algorithm\n",
    "4. We can use some other Vectorizer such TF-IDF vectorizer to calculate similarity.\n",
    "5. Or Maybe, our assumption that two links are similar if the count of words just before and after the link is same, is wrong. \n",
    "6. We can also use some features other than just word tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets try with TF-IDF vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', decode_error='ignore')\n",
    "vectordata = vectorizer.fit_transform(newdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lets try Robust Covariance Detector\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "clf = EllipticEnvelope(contamination=0.1)\n",
    "vectordata = vectordata.toarray()\n",
    "clf.fit(vectordata)\n",
    "y_pred = clf.decision_function(vectordata).ravel()\n",
    "threshold = stats.scoreatpercentile(y_pred, 100 * outliers_fraction)\n",
    "y_pred = y_pred > threshold\n",
    "imp_links = list(compress(linklabels, y_pred))\n",
    "imp_links[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
